# transformers_intro

This repo is a work in progress.

This will be a systematic introduction to Transformers with well chosen examples starting with basic concepts such as Back-propagation. We will dive into Sequential Models, looking into RNNs, LSTM models and Gated RNNs. We will wade through Latent Semantic Analsysis and will look more closely into the concept of Attention.  
